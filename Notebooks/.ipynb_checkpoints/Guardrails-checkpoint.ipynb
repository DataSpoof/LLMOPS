{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db53f4ed-e122-4a4b-b770-e5bb00806098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import duckdb\n",
    "from pydantic import BaseModel, Field\n",
    "from IPython.display import Markdown\n",
    "\n",
    "import phoenix as px\n",
    "import os\n",
    "from openinference.instrumentation.openai import OpenAIInstrumentor\n",
    "from opentelemetry.trace import Status, StatusCode\n",
    "from openinference.instrumentation import TracerProvider\n",
    "from phoenix.otel import register\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import re\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94985135-a95a-4aa8-869c-5b28a8f23366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Environment helpers ----------\n",
    "def load_env():\n",
    "    _ = load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "def get_openai_api_key():\n",
    "    openai_api_key = \"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\"\n",
    "    return openai_api_key\n",
    "\n",
    "\n",
    "\n",
    "def get_phoenix_endpoint():\n",
    "    phoenix_endpoint = \"http://localhost:6006/v1/traces\"\n",
    "    return phoenix_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbc2c50-57d8-49d6-a8b9-6f0737c47fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenTelemetry Tracing Details\n",
      "|  Phoenix Project: LLMEVALS\n",
      "|  Span Processor: SimpleSpanProcessor\n",
      "|  Collector Endpoint: http://localhost:6006/v1/traces\n",
      "|  Transport: HTTP + protobuf\n",
      "|  Transport Headers: {}\n",
      "|  \n",
      "|  Using a default SpanProcessor. `add_span_processor` will overwrite this default.\n",
      "|  \n",
      "|  WARNING: It is strongly advised to use a BatchSpanProcessor in production environments.\n",
      "|  \n",
      "|  `register` has set this TracerProvider as the global OpenTelemetry default.\n",
      "|  To disable this behavior, call `register` with `set_global_tracer_provider=False`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- Initialize client & tracing ----------\n",
    "openai_api_key = get_openai_api_key()\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "PROJECT_NAME = \"LLMEVALS\"\n",
    "tracer_provider = register(\n",
    "    project_name=PROJECT_NAME,\n",
    "    endpoint = get_phoenix_endpoint()\n",
    ")\n",
    "\n",
    "OpenAIInstrumentor().instrument(tracer_provider = tracer_provider)\n",
    "tracer = tracer_provider.get_tracer(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030a6c76-adda-455a-9962-d873d19246da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Constants / Files ----------\n",
    "TRANSACTION_DATA_FILE_PATH = 'Sales.parquet'\n",
    "\n",
    "# ---------- Guardrail helper functions ----------\n",
    "FORBIDDEN_SQL_TOKENS = [\n",
    "    r\"\\bDROP\\b\", r\"\\bDELETE\\b\", r\"\\bINSERT\\b\", r\"\\bUPDATE\\b\", r\"\\bALTER\\b\",\n",
    "    r\"\\bCREATE\\b\", r\"\\bTRUNCATE\\b\", r\";\", r\"`\", r\"--\", r\"/\\*\", r\"\\*/\"\n",
    "]\n",
    "\n",
    "# Basic set of SQL keywords for some token filtering heuristics (not exhaustive)\n",
    "SQL_KEYWORDS = {\n",
    "    \"select\",\"from\",\"where\",\"group\",\"by\",\"order\",\"join\",\"left\",\"right\",\"inner\",\"outer\",\n",
    "    \"on\",\"as\",\"limit\",\"having\",\"distinct\",\"union\",\"all\",\"with\",\"case\",\"when\",\"then\",\"else\",\"end\",\n",
    "    \"and\",\"or\",\"not\",\"in\",\"is\",\"null\",\"like\",\"between\",\"exists\",\"count\",\"sum\",\"avg\",\"min\",\"max\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f6dbf36-8124-4865-af20-09972c65f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_json_from_text(text: str) -> str:\n",
    "    \"\"\"Find the first JSON object in text and return it, else raise.\"\"\"\n",
    "    # Find first { and matching } naive approach:\n",
    "    start = text.find(\"{\")\n",
    "    if start == -1:\n",
    "        raise ValueError(\"No JSON object found in model response.\")\n",
    "    # Try to find the closing brace by simple balancing.\n",
    "    balance = 0\n",
    "    for i in range(start, len(text)):\n",
    "        if text[i] == \"{\":\n",
    "            balance += 1\n",
    "        elif text[i] == \"}\":\n",
    "            balance -= 1\n",
    "            if balance == 0:\n",
    "                json_text = text[start:i+1]\n",
    "                return json_text\n",
    "    raise ValueError(\"Could not extract JSON object from response.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc1764a-585d-4e66-900f-9ece5cbb3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def contains_forbidden_tokens(sql: str) -> List[str]:\n",
    "    found = []\n",
    "    for pattern in FORBIDDEN_SQL_TOKENS:\n",
    "        if re.search(pattern, sql, flags=re.IGNORECASE):\n",
    "            found.append(pattern)\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10447823-6e15-44ff-bce7-2387d8f0137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ensure_select_or_with(sql: str) -> bool:\n",
    "    # Strip leading whitespace and parentheses which may precede WITH/SELECT in some systems\n",
    "    stripped = sql.lstrip()\n",
    "    # allow \"WITH\" (CTE) or \"SELECT\"\n",
    "    return bool(re.match(r\"^(WITH|SELECT)\\b\", stripped, flags=re.IGNORECASE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8590d36f-1a89-41df-922b-965501102eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_single_statement(sql: str) -> bool:\n",
    "    # Simple check: no semicolons and not multiple \"SELECT\" tokens that imply multi-statements\n",
    "    if \";\" in sql:\n",
    "        return False\n",
    "    # allow multiple SELECT tokens inside subqueries; rely on forbidden tokens and other checks\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9240a60a-d33c-46cd-a3fa-058f9123c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_limit_clause(sql: str) -> str:\n",
    "    # If a LIMIT clause is present, return as-is. Else append LIMIT 1000\n",
    "    if re.search(r\"\\bLIMIT\\b\", sql, flags=re.IGNORECASE):\n",
    "        return sql\n",
    "    # Append LIMIT 1000 safely\n",
    "    return sql.strip() + \" LIMIT 1000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d953595b-2c26-4e39-8d0e-63aef67ed90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_referenced_columns(sql: str, allowed_columns: List[str]) -> List[str]:\n",
    "    # Return list of allowed_columns that appear in the SQL text as whole words.\n",
    "    used = []\n",
    "    for c in allowed_columns:\n",
    "        # match exact column with word boundaries; handle case-insensitivity\n",
    "        if re.search(r\"\\b\" + re.escape(c) + r\"\\b\", sql, flags=re.IGNORECASE):\n",
    "            used.append(c)\n",
    "    return used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e798a24d-a416-4dd4-a2e3-570f7b6f74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def validate_sql(sql: str, allowed_columns: List[str], table_name: str = \"sales\") -> Dict:\n",
    "    \"\"\"\n",
    "    Validate the SQL string. Returns dict {'ok': bool, 'message': str, 'sql': str}\n",
    "    On success 'sql' contains possibly modified SQL (e.g., with LIMIT appended).\n",
    "    \"\"\"\n",
    "    raw_sql = sql\n",
    "    # Basic checks\n",
    "    forbidden = contains_forbidden_tokens(raw_sql)\n",
    "    if forbidden:\n",
    "        return {\"ok\": False, \"message\": f\"Forbidden tokens present: {forbidden}\", \"sql\": None}\n",
    "\n",
    "    if not ensure_select_or_with(raw_sql):\n",
    "        return {\"ok\": False, \"message\": \"Only SELECT (or WITH ... SELECT ...) queries are allowed.\", \"sql\": None}\n",
    "\n",
    "    if not ensure_single_statement(raw_sql):\n",
    "        return {\"ok\": False, \"message\": \"Multiple statements or semicolons are not allowed.\", \"sql\": None}\n",
    "\n",
    "    # Check that table_name is referenced (optional, but recommended)\n",
    "    if not re.search(r\"\\b\" + re.escape(table_name) + r\"\\b\", raw_sql, flags=re.IGNORECASE):\n",
    "        # allow queries that reference df directly (we create sales table in DuckDB) â€” but require FROM or CTE referring to table\n",
    "        # Not strictly required; only warn if table_name missing:\n",
    "        return {\"ok\": False, \"message\": f\"Query must reference the table '{table_name}' in FROM clause.\", \"sql\": None}\n",
    "\n",
    "    # Ensure referenced columns are subset of allowed_columns:\n",
    "    used_columns = find_referenced_columns(raw_sql, allowed_columns)\n",
    "    # If the model referenced columns not in the allowed set, we may not detect them via simple approach.\n",
    "    # We defensively allow only columns from the allowed set to be present, but if a column-like token exists but not in allowed_columns\n",
    "    # our token scanning below is conservative: we'll search for identifiers and ensure they are either keywords, table name, functions, or allowed columns.\n",
    "    identifier_tokens = re.findall(r\"\\b([A-Za-z_][A-Za-z0-9_]*)\\b\", raw_sql)\n",
    "    unknown_identifiers = set()\n",
    "    for tok in identifier_tokens:\n",
    "        lower = tok.lower()\n",
    "        if lower in SQL_KEYWORDS:\n",
    "            continue\n",
    "        if lower == table_name.lower():\n",
    "            continue\n",
    "        # numeric-like tokens are filtered earlier; tokens that are in allowed_columns are fine\n",
    "        if any(tok.lower() == c.lower() for c in allowed_columns):\n",
    "            continue\n",
    "        # It's possibly a function name (COUNT, SUM) which are in SQL_KEYWORDS; we already filtered keywords.\n",
    "        # Anything else is suspicious.\n",
    "        unknown_identifiers.add(tok)\n",
    "\n",
    "    # Remove common benign tokens (like aliases 't' single-letter), allow single-letter aliases\n",
    "    unknown_identifiers = {u for u in unknown_identifiers if len(u) > 1 or u.lower() not in {\"t\",\"s\",\"a\",\"b\",\"c\",\"d\"}}\n",
    "    # But some functions may still be unknown; to avoid false positives, we require that at least one of the used_columns is present.\n",
    "    if not used_columns:\n",
    "        # No known columns referenced â€” reject.\n",
    "        return {\"ok\": False, \"message\": \"No known (whitelisted) columns were referenced. The query must use dataset columns.\", \"sql\": None}\n",
    "\n",
    "    # If there are suspicious unknown identifiers, reject to be safe\n",
    "    if unknown_identifiers:\n",
    "        return {\"ok\": False, \"message\": f\"Query contains unknown identifiers which may be unsafe: {sorted(list(unknown_identifiers))}\", \"sql\": None}\n",
    "\n",
    "    # Finally, ensure LIMIT\n",
    "    safe_sql = ensure_limit_clause(raw_sql)\n",
    "    return {\"ok\": True, \"message\": \"SQL validated\", \"sql\": safe_sql}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe2670b-81c0-4813-9075-e1f1ab64cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Prompt templates with guardrails ----------\n",
    "SQL_GENERATION_PROMPT = \"\"\"\n",
    "You are an assistant that generates SQL for querying a known table in a safe, auditable manner.\n",
    "\n",
    "Constraints (MUST follow exactly):\n",
    "1) Return only a single JSON object and nothing else. The JSON must have exactly one key: \"sql\".\n",
    "   Example:\n",
    "   {{ \"sql\": \"SELECT columnA, columnB FROM sales WHERE region = 'North' LIMIT 100\" }}\n",
    "\n",
    "2) The SQL must be a SELECT (or WITH ... SELECT) query only. No DDL/DML (DROP, DELETE, INSERT, UPDATE, ALTER, CREATE, TRUNCATE, etc.).\n",
    "3) Do not include any backticks, semicolons, comments (-- or /* */), or multiple statements.\n",
    "4) Use only the available columns: {columns}\n",
    "5) Reference the table name: {table_name}\n",
    "6) If you expect many rows, include a sensible LIMIT (we will still ensure a hard LIMIT of 1000).\n",
    "7) Do not include any surrounding markdown or extraneous text â€” only the JSON object.\n",
    "\n",
    "User prompt:\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "DATA_ANALYSIS_PROMPT = \"\"\"\n",
    "Analyze the following data: {data}\n",
    "Your job is to answer the following question: {prompt}\n",
    "Return a clear text response (no code required).\n",
    "\"\"\"\n",
    "\n",
    "CHART_CONFIGURATION_PROMPT = \"\"\"\n",
    "Generate a chart configuration based on this data: {data}\n",
    "The goal is to show: {visualization_goal}\n",
    "Return JSON-like object describing: chart_type, x_axis, y_axis, title.\n",
    "\"\"\"\n",
    "\n",
    "CREATE_CHART_PROMPT = \"\"\"\n",
    "Write python code to create a chart based on the following configuration.\n",
    "Only return the code, no other text.\n",
    "config: {config}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9090ce3b-d7d2-4010-9af0-6b7289c7a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- SQL generation and verification ----------\n",
    "def generate_sql_query(prompt: str, columns: List[str], table_name: str) -> str:\n",
    "    \"\"\"Ask the model to produce SQL but enforce JSON-only response; then parse and validate.\"\"\"\n",
    "    formatted_prompt = SQL_GENERATION_PROMPT.format(prompt=prompt, columns=\", \".join(columns), table_name=table_name)\n",
    "\n",
    "    # Use chat completions with explicit system/user roles to guide behavior\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a strict SQL generator.\"},\n",
    "            {\"role\": \"user\", \"content\": formatted_prompt},\n",
    "        ],\n",
    "        # No tools here; we want strict text response\n",
    "    )\n",
    "\n",
    "    raw_text = response.choices[0].message.content\n",
    "    # The model should return JSON; attempt to extract JSON object robustly\n",
    "    try:\n",
    "        json_text = extract_json_from_text(raw_text)\n",
    "        parsed = json.loads(json_text)\n",
    "        if \"sql\" not in parsed or not isinstance(parsed[\"sql\"], str):\n",
    "            raise ValueError(\"JSON does not contain 'sql' string field.\")\n",
    "        sql_candidate = parsed[\"sql\"].strip()\n",
    "    except Exception as e:\n",
    "        # If we couldn't parse JSON, raise explicit error so caller can handle\n",
    "        raise ValueError(f\"Failed to parse JSON from model response: {str(e)}. Raw response: {raw_text}\")\n",
    "\n",
    "    # Finally return SQL candidate (validation occurs later)\n",
    "    return sql_candidate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64df00f0-b22c-48ba-8bca-486dafcbaef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Tools implementations with guardrails ----------\n",
    "@tracer.tool()\n",
    "def lookup_sales_data(prompt: str) -> str:\n",
    "    \"\"\"Implementation of sales data lookup from parquet file using SQL, with guardrails.\"\"\"\n",
    "    try:\n",
    "        table_name = \"sales\"\n",
    "        # Load data\n",
    "        df = pd.read_parquet(TRANSACTION_DATA_FILE_PATH)\n",
    "        # Create DuckDB table\n",
    "        duckdb.sql(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM df\")\n",
    "\n",
    "        # Generate SQL via LLM (enforced JSON)\n",
    "        sql_query = generate_sql_query(prompt, list(df.columns), table_name)\n",
    "\n",
    "        # Basic cleaning\n",
    "        sql_query = sql_query.strip()\n",
    "        # Remove triple-backtick wrappers if any slipped through\n",
    "        sql_query = sql_query.replace(\"```sql\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        # Validate SQL guardrails\n",
    "        validation = validate_sql(sql_query, list(df.columns), table_name=table_name)\n",
    "        if not validation[\"ok\"]:\n",
    "            return f\"Error: SQL validation failed: {validation['message']}\"\n",
    "\n",
    "        safe_sql = validation[\"sql\"]\n",
    "\n",
    "        # Execute in DuckDB within tracer span\n",
    "        with tracer.start_as_current_span(\"execute_sql_query\", openinference_span_kind=\"chain\") as span:\n",
    "            try:\n",
    "                result_df = duckdb.sql(safe_sql).df()\n",
    "                span.set_output(value=str(result_df.head(10).to_string()))\n",
    "                span.set_status(StatusCode.OK)\n",
    "                # Return a concise textual representation (tool output)\n",
    "                return result_df.to_string()\n",
    "            except Exception as e:\n",
    "                span.set_status(StatusCode.ERROR)\n",
    "                return f\"Error executing SQL: {str(e)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error accessing data: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a15fff-63f0-4753-b940-aff4b823afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tracer.tool()\n",
    "def analyze_sales_data(prompt: str, data: str) -> str:\n",
    "    \"\"\"Implementation of AI-powered sales data analysis\"\"\"\n",
    "    formatted_prompt = DATA_ANALYSIS_PROMPT.format(data=data, prompt=prompt)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are an analysis assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "\n",
    "    analysis = response.choices[0].message.content\n",
    "    return analysis if analysis else \"No analysis could be generated\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cede6b-2a65-4e42-a7e4-01a7b1b0aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VisualizationConfig(BaseModel):\n",
    "    chart_type: str = Field(..., description=\"Type of chart to generate\")\n",
    "    x_axis: str = Field(..., description=\"Name of the x-axis column\")\n",
    "    y_axis: str = Field(..., description=\"Name of the y-axis column\")\n",
    "    title: str = Field(..., description=\"Title of the chart\")\n",
    "\n",
    "\n",
    "@tracer.chain()\n",
    "def extract_chart_config(data: str, visualization_goal: str) -> dict:\n",
    "    \"\"\"Generate chart visualization configuration\"\"\"\n",
    "    formatted_prompt = CHART_CONFIGURATION_PROMPT.format(data=data, visualization_goal=visualization_goal)\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a chart-config generator.\"},\n",
    "                  {\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "        response_format=VisualizationConfig,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        content = response.choices[0].message.content\n",
    "        return {\n",
    "            \"chart_type\": content.chart_type,\n",
    "            \"x_axis\": content.x_axis,\n",
    "            \"y_axis\": content.y_axis,\n",
    "            \"title\": content.title,\n",
    "            \"data\": data\n",
    "        }\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"chart_type\": \"line\",\n",
    "            \"x_axis\": \"date\",\n",
    "            \"y_axis\": \"value\",\n",
    "            \"title\": visualization_goal,\n",
    "            \"data\": data\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad487fd8-e503-488c-8137-4417f3527e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tracer.chain()\n",
    "def create_chart(config: dict) -> str:\n",
    "    formatted_prompt = CREATE_CHART_PROMPT.format(config=config)\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a Python code generator.\"},\n",
    "                  {\"role\": \"user\", \"content\": formatted_prompt}],\n",
    "    )\n",
    "    code = response.choices[0].message.content\n",
    "    code = code.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
    "    return code\n",
    "\n",
    "@tracer.tool()\n",
    "def generate_visualization(data: str, visualization_goal: str) -> str:\n",
    "    config = extract_chart_config(data, visualization_goal)\n",
    "    code = create_chart(config)\n",
    "    return code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8e86067-99d5-4683-821f-275f44318deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Tools metadata ----------\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_sales_data\",\n",
    "            \"description\": \"Look up data from Store Sales Price Elasticity Promotions dataset\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"analyze_sales_data\",\n",
    "            \"description\": \"Analyze sales data to extract insights\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"prompt\": {\"type\": \"string\", \"description\": \"The unchanged prompt that the user provided.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"prompt\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_visualization\",\n",
    "            \"description\": \"Generate Python code to create data visualizations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"string\", \"description\": \"The lookup_sales_data tool's output.\"},\n",
    "                    \"visualization_goal\": {\"type\": \"string\", \"description\": \"The goal of the visualization.\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"visualization_goal\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "tool_implementations = {\n",
    "    \"lookup_sales_data\": lookup_sales_data,\n",
    "    \"analyze_sales_data\": analyze_sales_data,\n",
    "    \"generate_visualization\": generate_visualization\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a8dbf7d-fb2c-4d78-b250-1198c4ac83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tracer.chain()\n",
    "def handle_tool_calls(tool_calls, messages):\n",
    "    for tool_call in tool_calls:\n",
    "        function = tool_implementations[tool_call.function.name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        result = function(**function_args)\n",
    "        messages.append({\"role\": \"tool\", \"content\": result, \"tool_call_id\": tool_call.id})\n",
    "    return messages\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful assistant that can answer questions about the Store Sales Price Elasticity Promotions dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f12811ff-b14a-4b5a-9f98-9ab8a4794274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_agent(messages):\n",
    "    print(\"Running agent with messages:\", messages)\n",
    "    if isinstance(messages, str):\n",
    "        messages = [{\"role\": \"user\", \"content\": messages}]\n",
    "    if not any(\n",
    "            isinstance(message, dict) and message.get(\"role\") == \"system\" for message in messages\n",
    "        ):\n",
    "            system_prompt = {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
    "            messages.append(system_prompt)\n",
    "\n",
    "    while True:\n",
    "        print(\"Starting router call span\")\n",
    "        with tracer.start_as_current_span(\n",
    "            \"router_call\",\n",
    "            openinference_span_kind=\"chain\",\n",
    "        ) as span:\n",
    "            span.set_input(value=messages)\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "            )\n",
    "            messages.append(response.choices[0].message.model_dump())\n",
    "            tool_calls = response.choices[0].message.tool_calls\n",
    "            print(\"Received response with tool calls:\", bool(tool_calls))\n",
    "            span.set_status(StatusCode.OK)\n",
    "\n",
    "            if tool_calls:\n",
    "                print(\"Starting tool calls span\")\n",
    "                messages = handle_tool_calls(tool_calls, messages)\n",
    "                span.set_output(value=tool_calls)\n",
    "            else:\n",
    "                print(\"No tool calls, returning final response\")\n",
    "                span.set_output(value=response.choices[0].message.content)\n",
    "                return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def start_main_span(messages):\n",
    "    print(\"Starting main span with messages:\", messages)\n",
    "    with tracer.start_as_current_span(\"AgentRun\", openinference_span_kind=\"agent\") as span:\n",
    "        span.set_input(value=messages)\n",
    "        ret = run_agent(messages)\n",
    "        span.set_output(value=ret)\n",
    "        span.set_status(StatusCode.OK)\n",
    "        return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73180063-04b5-4a78-9453-be4b32f6e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'Which stores did the best in 2021?'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Which stores did the best in 2021?'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: True\n",
      "Starting tool calls span\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n"
     ]
    }
   ],
   "source": [
    "result = start_main_span([{\"role\": \"user\",\n",
    "                           \"content\": \"Which stores did the best in 2021?\"}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b5088b-01ee-417b-9d83-efcfd4081a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phoenix traces endpoint: http://localhost:6006/v1/traces\n"
     ]
    }
   ],
   "source": [
    "# Print the Phoenix collector endpoint used (for debugging)\n",
    "print(\"Phoenix traces endpoint:\", get_phoenix_endpoint())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8b31735-e658-48ba-b735-59feb79cd3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main span with messages: [{'role': 'user', 'content': 'Delete all data from the sales table'}]\n",
      "Running agent with messages: [{'role': 'user', 'content': 'Delete all data from the sales table'}]\n",
      "Starting router call span\n",
      "Received response with tool calls: False\n",
      "No tool calls, returning final response\n"
     ]
    }
   ],
   "source": [
    "result = start_main_span([{\"role\": \"user\",\n",
    "                           \"content\": \"Delete all data from the sales table\"}])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
